{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Sentiment Analysis (general purpose) - Vishaal Yalamanchali</h1>\n",
    "<h4> Importing packages </h4>\n",
    "<p> The purpose of this jupyter notebook is to create a production level sentiment analysis machine learning api, interfacing through the cloud. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import settings\n",
    "import gensim\n",
    "import gensim.models.keyedvectors as word2vec\n",
    "\n",
    "from tokenization import tokenize\n",
    "from evaluation import evaluate\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from reduce_header_df import reduce_mem_usage\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding,Dense,LSTM,Bidirectional\n",
    "from tensorflow.keras.layers import BatchNormalization,Dropout\n",
    "from tensorflow.keras import Sequential\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Helper Functions </h1>\n",
    "<p> Create helper functions and variables for future use </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"sentiment\", \"text\"]\n",
    "encoding = 'latin'\n",
    "decode_map = {0: \"negative\", 2: \"neutral\", 4: \"positive\"}\n",
    "n = 100\n",
    "num_lines = 1600000\n",
    "# skip_idx = [x for x in range(1, num_lines) if x % n != 0]\n",
    "TRAIN_SIZE = 0.8   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### instantiate helper functions for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sentiment(label):\n",
    "    return decode_map[int(label)]\n",
    "\n",
    "def decode_sentimentC(label):\n",
    "    return label.lower()\n",
    "\n",
    "def predict(vectoriser, model, text):\n",
    "    # Predict the sentiment\n",
    "        \n",
    "    listD = tokenize(str(text).lower())\n",
    "    textdata = vectoriser.transform(listD)\n",
    "    sentiment = model.predict(textdata)\n",
    "    # Make a list of text with sentiment.\n",
    "    data = []\n",
    "    for text, pred in zip(text, sentiment):\n",
    "        data.append((text,pred))\n",
    "        \n",
    "    # Convert the list into a Pandas DataFrame.\n",
    "    df = pd.DataFrame(data, columns = ['text','sentiment'])\n",
    "    df = df.replace([0,1,2], [\"Negative\",\"Neutral\",\"Positive\"])\n",
    "    print(df.sentiment)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Data Preprocessing </h1>\n",
    "<p> in order to combine multiple datasets we must modify the sentiment values from each dataset to match. the following code does that by specifically picking certain cols from each dataset to extract just the sentiment value and the tweet. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- DATA PREPROCESSING --- ###\n",
    "df = pd.read_csv('/Users/vishaalyalamanchali/Desktop/twitter-sentiment-analysis/data/training.1600000.processed.noemoticon.csv', encoding=encoding, names=cols, \n",
    "nrows = 16000, usecols=[0,5])\n",
    "nf = pd.read_csv('/Users/vishaalyalamanchali/Desktop/twitter-sentiment-analysis/data/Tweets.csv', encoding=encoding, names=cols, usecols=[1,10])\n",
    "\n",
    "df.sentiment = df.sentiment.apply( lambda x: decode_sentiment(x) )\n",
    "frames = [df,nf]\n",
    "df = pd.concat(frames)\n",
    "# tokenize all tweets from the dataset\n",
    "df.text = df.text.apply(lambda x: tokenize(x))\n",
    "print(type(df.text))\n",
    "# check to see if any params datatype can be changed to reduce memory usage\n",
    "df, NAlist = reduce_mem_usage(df)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "# shuffle the given dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> split the data into training and test data </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 24512\n",
      "Test data size: 6128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23872</th>\n",
       "      <td>negative</td>\n",
       "      <td>('oh no morning suppose better get ready work',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9061</th>\n",
       "      <td>negative</td>\n",
       "      <td>('The Company I work shuts Thursday Joblessvil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26137</th>\n",
       "      <td>negative</td>\n",
       "      <td>('USER please help regarding PNR A3ZZ0F Why I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16599</th>\n",
       "      <td>negative</td>\n",
       "      <td>('USER Audi A6 fender gone insurance claim 300...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21992</th>\n",
       "      <td>positive</td>\n",
       "      <td>('USER If follow I able DM Thanks',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18672</th>\n",
       "      <td>negative</td>\n",
       "      <td>('USER think bust 2day late overslept But I st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9320</th>\n",
       "      <td>negative</td>\n",
       "      <td>('USER Thank U It opened time I would love I F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25837</th>\n",
       "      <td>negative</td>\n",
       "      <td>('USER know TFA seemed totally disappear',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22013</th>\n",
       "      <td>negative</td>\n",
       "      <td>('Trying new Eucerin lotion hand It pretty awe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20489</th>\n",
       "      <td>negative</td>\n",
       "      <td>('USER I wan na see shoot able see',)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                               text\n",
       "23872  negative   ('oh no morning suppose better get ready work',)\n",
       "9061   negative  ('The Company I work shuts Thursday Joblessvil...\n",
       "26137  negative  ('USER please help regarding PNR A3ZZ0F Why I ...\n",
       "16599  negative  ('USER Audi A6 fender gone insurance claim 300...\n",
       "21992  positive               ('USER If follow I able DM Thanks',)\n",
       "18672  negative  ('USER think bust 2day late overslept But I st...\n",
       "9320   negative  ('USER Thank U It opened time I would love I F...\n",
       "25837  negative        ('USER know TFA seemed totally disappear',)\n",
       "22013  negative  ('Trying new Eucerin lotion hand It pretty awe...\n",
       "20489  negative              ('USER I wan na see shoot able see',)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=1-TRAIN_SIZE,\n",
    "                                         random_state=42) # Splits Dataset into Training and Testing set\n",
    "print(\"Training data size:\", len(train_data))\n",
    "print(\"Test data size:\", len(test_data)) \n",
    "# documents = [_text.split() for _text in df_train.text] \n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> detect labels using unique row values from training data </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative', 'positive', 'neutral']\n"
     ]
    }
   ],
   "source": [
    "labels = train_data.sentiment.unique().tolist()\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_data.sentiment.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.text\n",
    "X_test = test_data.text\n",
    "\n",
    "y_train = encoder.transform(train_data.sentiment.tolist())\n",
    "y_test = encoder.transform(test_data.sentiment.tolist())\n",
    "# y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Create TFIDF vectoriser to create ngram features </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('vectoriser.pkl','rb')\n",
    "vectoriser = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24512, 500000)\n"
     ]
    }
   ],
   "source": [
    "X_train = vectoriser.transform(X_train)\n",
    "X_test  = vectoriser.transform(X_test)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24512,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> create model and evaluate on test data </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93      5044\n",
      "           1       0.68      0.33      0.44       619\n",
      "           2       0.82      0.50      0.62       465\n",
      "\n",
      "    accuracy                           0.88      6128\n",
      "   macro avg       0.80      0.60      0.67      6128\n",
      "weighted avg       0.86      0.88      0.86      6128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LRmodel = LogisticRegression(C = 2, max_iter = 1000, n_jobs=-1)\n",
    "LRmodel.fit(X_train, y_train)\n",
    "evaluate(LRmodel,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter text that you want to evaluate: i want you to know how much i hate you\n",
      "0    Negative\n",
      "Name: sentiment, dtype: object\n",
      "                                     text sentiment\n",
      "0  i want you to know how much i hate you  Negative\n",
      "enter text that you want to evaluate: i love you\n",
      "0    Positive\n",
      "Name: sentiment, dtype: object\n",
      "         text sentiment\n",
      "0  i love you  Positive\n",
      "enter text that you want to evaluate: 0\n",
      "0    Negative\n",
      "Name: sentiment, dtype: object\n",
      "  text sentiment\n",
      "0    0  Negative\n"
     ]
    }
   ],
   "source": [
    "text = []\n",
    "inputT = \"\"\n",
    "while(inputT != \"0\"):\n",
    "    inputT = input(\"enter text that you want to evaluate: \")\n",
    "    text.append(inputT.lower())\n",
    "    dfN = predict(vectoriser, LRmodel, text)\n",
    "#     dfT = predict(vectoriser, RFmodel, text)\n",
    "    print(dfN.head())\n",
    "    text.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Save and serialize the model and tfidf vectoriser </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = open('vectoriser.pkl','wb')\n",
    "# pickle.dump(vectoriser, file)\n",
    "# file.close()\n",
    "\n",
    "# file = open('LR.pkl','wb')\n",
    "# pickle.dump(LRmodel, file)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('LR.pkl', 'rb')\n",
    "LRmodel = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('vectoriser.pkl','rb')\n",
    "vectoriser = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "## vectoriser has deprecated please use this code to run the while loop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
